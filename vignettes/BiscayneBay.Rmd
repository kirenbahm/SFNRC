---
title: 'Water quality in Biscayne Bay: Status and trends'
subtitle: ''
output: 
  pdf_document: 
    latex_engine: pdflatex
vignette: >
  %\VignetteIndexEntry{DataForEver}
  %\VignetteEngine{knitr::knitr}
  %\usepackage[UTF-8]{inputenc}
mainfont: FreeMono
header-includes:
- \usepackage{pdflscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
- \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE, echo=FALSE}

### TODO: amend bnpMod to include bay subregions used for regulatory water quality criteria, or include additional polygon files in package



if(!require(knitr)){
  install.packages("knitr", repos='http://cran.us.r-project.org')
}
if(!require(rmarkdown)){
  install.packages("rmarkdown", repos='http://cran.us.r-project.org')
}
if(!require(plyr)){
  install.packages("plyr", repos='http://cran.us.r-project.org')
}
if(!require(reshape2)){
  install.packages("reshape2", repos='http://cran.us.r-project.org')
}
if(!require(ggplot2)){
  install.packages("ggplot2", repos='http://cran.us.r-project.org')
}
if(!require(scales)){
  install.packages("scales", repos='http://cran.us.r-project.org')
}
if(!require(maptools)){ # this package may be unnecessary
  install.packages("scales", repos='http://cran.us.r-project.org')
}
if(!require(rgeos)){
  install.packages("rgeos", repos='http://cran.us.r-project.org')
}
if(!require(deldir)){
  install.packages("deldir", repos='http://cran.us.r-project.org')
}
if(!require(doMC)){
  install.packages("doMC", repos='http://cran.us.r-project.org')
}
if(!require(foreach)){
  install.packages("foreach", repos='http://cran.us.r-project.org')
}
if(!require(zoo)){
  install.packages("zoo", repos='http://cran.us.r-project.org')
}

# then load the package:
library(doMC)
library(foreach)
library(knitr)
library(rmarkdown)
library(plyr)
library(zoo)
library(reshape2)
library(ggplot2)
library(scales)
library(SFNRC)

library(maptools)
library(rgeos)
library(sp)
library(dismo)
library(deldir)
library(gstat)
library(rgdal)
library(raster)

knitr::opts_chunk$set(echo = TRUE, comment=NA)
```

## Summary

Water quality trends in Biscayne Bay were evaluated using data from DataForEver and the Miami-Dade Department of Environmental Resources Management. Spatial and temporal trends were evaluated for subregions of the bay using interpolated raster layers for each water quality parameter. This approach minimizes, but does not eliminate, artifacts introduced by varying sampling locations. The effect of canal inflows on water quality in Biscayne Bay was also evaluated.


\vspace{3mm}\hrule

**Keywords:** Biscayne Bay, water quality


```{r, echo = FALSE, include=FALSE}
# if the NitrogenUptake2016 package isn't installed, use devtools to do so:
# devtools::install_github("troyhill/NitrogenUptake2016")

# set some constants
rasterFolder <- "/opt/physical/troy/RDATA/output/WQrasters/"
todaysDate <- substr(as.character(Sys.time()), 1, 10)
pointSize <- 2 # for ggplot graphics
pd <- pd2 <- position_dodge(1.2)
pd3 <- position_dodge(0.8)
grayColor <- 0.55
fig2Col   <- "gray55"
minPoints <- 8 # minimum number of sampling points required for interpolation
polygonLayer <- bnpMod # shapefile to be used for subsetting data, interpolation, etc.

compareParams <- c("AMMONIA-N", "NITRATE+NITRITE-N",
                   "SALINITY", "PH, FIELD", "CHLOROPHYLL-A", "TURBIDITY", "DISSOLVED OXYGEN", 
                   "PHOSPHATE, TOTAL AS P", "PHOSPHATE, ORTHO AS P")

## compiled water quality data - regenerate this.
summary(finDat)  # bay water quality data - merged with latest DERM data
summary(wqDat)   # canal water quality data (DERM data not likely to be relevant)

## hydrology data
summary(hydDat)  # canal inflows


registerDoMC(cores = 2) # register multicore parallel backend with the foreach package.
useMC = TRUE # sent to ddply calls, whether multiple cores should be used

```



## Water quality trends in Biscayne Bay


**1.1 Annual water quality trends in Biscayne Bay**

- Calculated annual geometric means, by station, for each calendar year

- Interpolated over entire bay, then extracted summary statistics for subregions

- Statistical analysis of trends: loess decomposition, breakpoints


```{r interpolated water quality rasters, echo=FALSE, include=FALSE}

# http://rspatial.org/analysis/rst/4-interpolation.html ------------------
fin2 <- dcast(finDat[, -c(4, 7)], stn + date + year ~ param) # long to wide
fin2 <- seas(fin2, timeCol = "date")
fin2$seas2  <- paste0(fin2$waterYr,"-", fin2$seas)


# Create interpolated maps of annual geometric means ----------------------
### Data are not finalized, so this is just laying out the conceptual approach. Interpolate for the whole bay and then clip for regions.
agm <- plyr::ddply(fin2[, -c(2)], plyr::.(year, stn), plyr::numcolwise(geoMean))
names(agm) <- gsub(x = names(agm), pattern = " |,", replacement = "")
names(agm) <- gsub(x = names(agm), pattern = "-|[+]", replacement = ".")


finDat.coords <- plyr::join_all(list(agm, as.data.frame(masterCoords)), by = "stn")
finDat.coords <- finDat.coords[!is.na(finDat.coords$long), ]

coordinates(finDat.coords) <- c("long", "lat")
proj4string(finDat.coords) <- CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")

sitesInBay <- sp::over(finDat.coords, polygonLayer)
sitesInBay <- finDat.coords[complete.cases(sitesInBay), ]



# kriging --------------------------------------------------------------
# biscInterp(inputData = sitesInBay,paramCol = "SALINITY", year = "2016")
    
    ### store raster layer in working environment
# biscRas <- biscInterp(inputData = sitesInBay,
    # paramCol = "SALINITY", year = "2016", returnRas = TRUE)


# ### 
# targParam <- "SALINITY"
# targYear  <- "2016"
# a <- biscInterp(inputData = sitesInBay, 
#            paramCol = targParam, year = targYear, yearCol = "year", returnRas = TRUE)
           
for (j in 4:(length(names(sitesInBay)))) {
  # dat.l <- list()
  for (i in 1:length(unique(sitesInBay$year))) {
    targYear  <- unique(sitesInBay$year)[i]
    targParam <- names(sitesInBay)[j] # "SALINITY" 
    targDat   <- sitesInBay
    lims      <- as.numeric(quantile(data.frame(targDat@data[, targParam]), c(0, 1), na.rm = TRUE))
    rasterFileAddr  <- paste0(rasterFolder, targParam, targYear, ".tif")
    csvMeanFileAddr <- paste0(rasterFolder, "mean/", targParam, targYear)
    csvSDFileAddr   <- paste0(rasterFolder, "sd/",   targParam, targYear)
    csvSub20FileAddr<- paste0(rasterFolder, "sub20/",   targParam, targYear)
    # if (!rasterFileAddr %in% list.files(rasterFolder, full.names = TRUE)) {
          tryCatch({
      dat.l <- biscInterp(inputData = targDat, paramCol = targParam, year = targYear, yearCol = "year", plotZLims = lims, returnRas = TRUE, exportRaster = TRUE, fileName = rasterFileAddr, minDataPoints = minPoints, BISCmap = polygonLayer)
      write.csv(x = t(extract(dat.l , polygonLayer, fun = mean, na.rm = TRUE)), file = csvMeanFileAddr, row.names = FALSE)
      write.csv(x = t(extract(dat.l , polygonLayer, fun = sd, na.rm = TRUE)), file =  csvSDFileAddr, row.names = FALSE)
      if(targParam %in% "SALINITY") {
        write.csv(x = t(extract(dat.l, polygonLayer, fun = function(x, ...) ecdf(x)(20), na.rm = TRUE)), file =  csvSub20FileAddr, row.names = FALSE)
      }}, error = function(e) {
            cat("error in outer loop for ", targParam, 
                targYear, ":", conditionMessage(e), "\n")
        })
    # }

  }
}
    ### summarize data after compiling rasters for each parameter
    # https://gis.stackexchange.com/questions/270988/raster-data-extract-to-polygon-rcode
    # possible approach would be to create a raster stack (https://gis.stackexchange.com/questions/29118/how-to-find-the-average-raster-value-of-an-area-defined-by-a-shapefile-using-r)
    # get mean and area <20 psu for bay subregions 
    ### example for entire raster:
    # test     <- ldply(dat.l, function(x) cellStats(x, "mean"))


### Or, load & process rasters from folder
meanList        <- list.files(paste0(rasterFolder, "/mean"), full.names = TRUE)
adat       <- lapply(X = meanList, FUN = read.csv) # build a list with all rasters in the folder
adat       <- do.call("rbind", adat)
names(adat) <- gsub(x = names(adat), pattern = "V", replacement = "")
adat$".id" <- gsub(x = meanList, pattern = paste0(rasterFolder, "mean/"), replacement = "")

sdList             <- list.files(paste0(rasterFolder, "/sd"), full.names = TRUE)
adat.sd       <- lapply(X = sdList, FUN = read.csv) # build a list with all rasters in the folder
adat.sd       <- do.call("rbind", adat.sd)
names(adat.sd) <- gsub(x = names(adat.sd), pattern = "V", replacement = "")
adat.sd$".id" <- gsub(x = sdList, pattern = paste0(rasterFolder, "sd/"), replacement = "")
                              

sub20List          <- list.files(paste0(rasterFolder, "/sub20"), full.names = TRUE)
adat.20       <- lapply(X = sub20List, FUN = read.csv) # build a list with all rasters in the folder
adat.20       <- do.call("rbind", adat.20)
names(adat.20) <- gsub(x = names(adat.20), pattern = "V", replacement = "")
adat.20$".id" <- gsub(x = sub20List, pattern = paste0(rasterFolder, "sub20/"), replacement = "")
 
# 
# rasList <- list.files(rasterFolder, pattern = ".tif$", full.names = TRUE)
# dat.l <- lapply(X = rasList, FUN = raster) # build a list with all rasters in the folder
#     adat    <- ldply(dat.l, function(x) t(extract(x, polygonLayer, fun = mean, na.rm = TRUE)), .parallel = useMC)
#     adat.20 <- ldply(dat.l[grep(pattern = "SALINITY", x = rasList)], function(x) t(extract(x, polygonLayer, fun = function(x,...)ecdf(x)(20), na.rm = TRUE)), .parallel = useMC)
#     # adat.20 <- ldply(dat.l, function(x) t(extract(x, polygonLayer, fun = function(x,...)ecdf(x)(20), na.rm = TRUE)))
#     adat.sd <- ldply(dat.l, function(x) t(raster::extract(x, polygonLayer, fun = sd, na.rm = TRUE)), .parallel = useMC)
# adat$'.id' <- adat.20$'.id' <- adat.sd$'.id' <- gsub(x = gsub(x = rasList, pattern = rasterFolder, replacement = ""), pattern = ".tif", replacement = "") # names
# ##

### to make a long dataset with columns: param, year, loc, mean, sd, ecdf20
combd <- join_all(list(
  melt(adat,    id.vars = ".id", variable.name = "subRegion", value.name = "mean"),
  melt(adat.sd, id.vars = ".id", variable.name = "subRegion", value.name = "sd"),
  melt(adat.20, id.vars = ".id", variable.name = "subRegion", value.name = "propSub20")
))



combd$param <- substr(combd[, ".id"], 1, nchar(combd[, ".id"]) - 4)
combd$yr    <- as.numeric(substr(combd[, ".id"], nchar(combd[, ".id"]) - 3, nchar(combd[, ".id"])))

### change subregion from region number to BOX_CODE (can easily be replaced by another column)
combd$subRegion <- as.character(polygonLayer@data$BOX_CODE)[as.numeric(as.character(combd$subRegion))]


# ggplot(combd, aes(y = mean, x = yr, col = subregion)) + geom_point() + geom_pointrange(aes(ymin = mean - sd, ymax = mean + sd)) + theme_classic() + facet_grid(param ~ ., scales = "free_y") + ylab("")

### I can't figure out how to generate multiple columns at the same time, avoiding the need to join_all. e.g., this doesn't work:
# test <- ldply(sal.list, summarise,
#               # name = names(x),
#               mean = function(x) cellStats(x, "mean"),
#               area_sub20 = function(x) cellStats(x, "ecdf(x)(20)"))

# 
# ### now repeat for all parameters
# wq.list <- list()
# for (j in 4:(length(names(sitesInBay)) - 1)) {
#   for (i in 1:length(unique(sitesInBay$year))) {
#     targYear  <- unique(sitesInBay$year)[i]
#     targParam <- names(sitesInBay)[j]
#     targDat   <- sitesInBay
#     lims      <- as.numeric(quantile(data.frame(targDat@data[, targParam]), c(0, 1), na.rm = TRUE))
#     wq.list[i] <- biscInterp(inputData = targDat, paramCol = targParam, year = targYear, yearCol = "year", plotZLims = lims,returnRas = TRUE)
#     names(wq.list)[i] <- paste0(targParam, targYear)
#   }
# }
# 
# test <- ldply(wq.list, function(x) cellStats(x, "mean"))

```



```{r Subregion map, fig.width = 4, fig.height = 4, message = FALSE, echo=FALSE}
par(mar = c(4,4,0.5,0.5))
cols.sub <- colors()[grep(x = colors(), pattern = "yellow|cyan|red|blue|green|brown")]
cols <- cols.sub[sample(x =  length(cols.sub), size = length(unique(polygonLayer@data$BOX_CODE)))]
cols <- cols.sub[sample(x =  length(cols.sub), size = length(unique(polygonLayer@data$BOX_CODE)))]

plot(polygonLayer, col = cols)
pointLabel(coordinates(polygonLayer), labels = polygonLayer$BOX_CODE)

```
Figure 1. Map of sub-regions used in Biscayne Bay, with numeric labels. 



```{r parameter trends, fig.width = 6, fig.height = 4, message = FALSE, echo=FALSE}
ggplot(combd, aes(y = mean, x = yr, col = subRegion)) + #geom_point(size  = 1, position = pd3) + 
  geom_pointrange(aes(ymin = mean - sd, ymax = mean + sd), position = pd3, fatten = 1) + theme_classic() + facet_grid(param ~ ., scales = "free_y") + ylab("") 

```
Figure 2. Annual water quality trends for Biscayne Bay subregions. Spatially-weighted mean (+- SD) of interpolated annual geometric means from individual stations.





**1.1.	 Annual trends in wet season water quality **
```{r interpolated wet season data, echo = FALSE, include = FALSE, message = FALSE}
### same as above but for wet season.
### memory constraints may require saving rasters to disk or instantly summarizing & deleting them
fin2 <- dcast(finDat[, -c(4, 7)], stn + date + year ~ param) # long to wide
fin2 <- seas(fin2, timeCol = "date")
fin2$seas2  <- paste0(fin2$waterYr,"-", fin2$seas)


# Create interpolated maps of geometric means ----------------------
agm <- plyr::ddply(fin2[, -c(grep(x = names(fin2), pattern = "date|water"))], plyr::.(seas2, seas, stn), plyr::numcolwise(geoMean))
names(agm) <- gsub(x = names(agm), pattern = " |,", replacement = "")
names(agm) <- gsub(x = names(agm), pattern = "-|[+]", replacement = ".")


finDat.coords <- plyr::join_all(list(agm, as.data.frame(masterCoords)), by = "stn")
finDat.coords <- finDat.coords[!is.na(finDat.coords$long), ]

coordinates(finDat.coords) <- c("long", "lat")
proj4string(finDat.coords) <- CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")

sitesInBay <- sp::over(finDat.coords, polygonLayer)
sitesInBay <- finDat.coords[complete.cases(sitesInBay), ]


for (j in 4:(length(names(sitesInBay)))) {
  # seas.l <- list()
  for (i in 1:length(unique(sitesInBay$seas2))) {
    targYear  <- unique(sitesInBay$seas2)[i]
    targParam <- names(sitesInBay)[j] # "SALINITY" 
    targDat   <- sitesInBay
    lims      <- as.numeric(quantile(data.frame(targDat@data[, targParam]), c(0, 1), na.rm = TRUE))
    
    rasterFileAddr   <- paste0(rasterFolder, "seas/", targParam, targYear, ".tif")
    csvMeanFileAddr  <- paste0(rasterFolder, "seas/mean/", targParam, targYear)
    csvSDFileAddr    <- paste0(rasterFolder, "seas/sd/", targParam, targYear)
    csvsub20FileAddr <- paste0(rasterFolder, "seas/sub20/", targParam, targYear)
    # if (!rasterFileAddr %in% list.files(paste0(rasterFolder, "seas/"),  full.names = TRUE)) { # if you don't want to re-process/overwrite files
          tryCatch({
      seas.l <- biscInterp(inputData = targDat, paramCol = targParam, year = targYear, yearCol = "seas2", plotZLims = lims, 
                       returnRas = TRUE, exportRaster = TRUE, fileName = rasterFileAddr, minDataPoints = minPoints, BISCmap = polygonLayer)
      write.csv(x = t(extract( seas.l, polygonLayer, fun = mean, na.rm = TRUE)), file = csvMeanFileAddr, row.names = FALSE) # record results 
      write.csv(x = t(extract( seas.l, polygonLayer, fun = sd, na.rm = TRUE)), file =  csvSDFileAddr, row.names = FALSE)
      if(targParam %in% "SALINITY") {
        write.csv(x = t(extract( seas.l, polygonLayer, fun = function(x, ...) ecdf(x)(20), na.rm = TRUE)), file =  csvSDFileAddr, row.names = FALSE)
      }
      
      }, error = function(e) {
            cat("error in outer loop for ", targParam, 
                targYear, ":", conditionMessage(e), "\n")
        })
    # }
  }}


### Load & process rasters from folder [this will change to a do.call/read.csv approach]
meanList        <- list.files(paste0(rasterFolder, "seas/mean"), full.names = TRUE)
adat.seas       <- lapply(X = meanList, FUN = read.csv) # build a list with all rasters in the folder
adat.seas       <- do.call("rbind", adat.seas)
names(adat.seas) <- gsub(x = names(adat.seas), pattern = "V", replacement = "")
adat.seas$".id" <- gsub(x = meanList, pattern = paste0(rasterFolder, "seas/mean/"), replacement = "")

sdList             <- list.files(paste0(rasterFolder, "seas/sd"), full.names = TRUE)
adat.seas.sd       <- lapply(X = sdList, FUN = read.csv) # build a list with all rasters in the folder
adat.seas.sd       <- do.call("rbind", adat.seas.sd)
names(adat.seas.sd) <- gsub(x = names(adat.seas.sd), pattern = "V", replacement = "")
adat.seas.sd$".id" <- gsub(x = sdList, pattern = paste0(rasterFolder, "seas/sd/"), replacement = "")
                              

sub20List          <- list.files(paste0(rasterFolder, "seas/sub20"), full.names = TRUE)
adat.seas.20       <- lapply(X = sub20List, FUN = read.csv) # build a list with all rasters in the folder
adat.seas.20       <- do.call("rbind", adat.seas.20)
names(adat.seas.20) <- gsub(x = names(adat.seas.20), pattern = "V", replacement = "")
adat.seas.20$".id" <- gsub(x = sub20List, pattern = paste0(rasterFolder, "seas/sub20/"), replacement = "")
                              


### to make a long dataset with columns: param, year, loc, mean, sd, ecdf20

combd.seas <- join_all(list(
  melt(adat.seas, id.vars = '.id', variable.name = "subRegion", value.name = "mean"),
  melt(adat.seas.sd, id.vars = '.id', variable.name = "subRegion", value.name = "sd") ,
  melt(adat.seas.20, id.vars = '.id', variable.name = "subRegion", value.name = "propSub20")
))

combd.seas$param <- substr(combd.seas[, '.id'], 1, nchar(combd.seas[, '.id']) - 8)
combd.seas$yr    <- as.numeric(substr(combd.seas[, 1], nchar(combd.seas[, 1]) - 7, nchar(combd.seas[, '.id']) - 4))
combd.seas$seas  <- substr(combd.seas[, '.id'], nchar(combd.seas[, '.id']) - 2, nchar(combd.seas[, '.id']))


### change subregion from region number to subRegion (can easily be replaced by another column)
combd.seas$subregion <- as.character(polygonLayer@data$BOX_CODE)[as.numeric(as.character(combd.seas$subRegion))]


```


```{r annual wet/dry season trends, fig.width = 7, fig.height = 4, message = FALSE, echo=FALSE}
ggplot(combd.seas, aes(y = mean, x = yr, col = subregion)) + #geom_point(size  = 0.25, position = pd3) + 
  geom_pointrange(aes(ymin = mean - sd, ymax = mean + sd), position = pd3, fatten = 1) + theme_classic() + facet_grid(param ~ seas, scales = "free_y") + ylab("") 

```

**1.2.	 Annual trends in dry season water quality **



**1.3.	 Monthly trends in water quality **

Will run into serious memory issues



## 2. Effect of canals

**2.1.	 Quantifying water inflows**


```{r annual water inflows from canals, include=FALSE, echo=FALSE}
# Prep canal water quality data for merging with flows --------------------------------
wqCanal <- reshape(wqDat[wqDat$param %in% compareParams, c("stn", "date", "param", "value")], id.vars = c("stn", "date") ) # # limit to relevant params and reshape dataset

wqCanal <- stats::reshape(wqDat[wqDat$param %in% compareParams, c("stn", "date", "param", "value")], idvar = c("stn", "date"), 
            timevar = "param", direction = "wide")
names(wqCanal) <- gsub(x = names(wqCanal), pattern = "value.", 
            replacement = "")

# Comparison of water inflows and salinity --------------------------------
### TODO: assign structures to subregions based on proximity to polygons in bnp
# https://stackoverflow.com/questions/26308426/how-do-i-find-the-polygon-nearest-to-a-point-in-r
structs <- c("S22", "S25", "S25A", "S25B", "S26", # central
             "S27", "S28", "S29", # from SWIM plan - north biscayne bay
             "G58", "S700", "G93", # new structures since SWIM plan?
             "S123",  "S21A", "S21", "S20", "S20F", "S20G", "S197") # south bay "MOWRY C"?
biscHyd <- hydDat[hydDat$stn %in% structs, ]
### add coordinates for polygon assignment
biscHyd <- join_all(list(biscHyd, as.data.frame(masterCoords)), by = "stn")
biscHyd <- join_all(list(biscHyd, wqCanal), by = c("stn", "date"))



biscHyd$kacft <- biscHyd$flow * 2.29569e-5 / 1000 * 60 * 60 * 24 # convert cfs to thousand acre feet per day
biscHyd$m3d   <- biscHyd$flow * 2446.58 # convert cfs to cubic meters per day
biscHyd       <- seas(biscHyd, timeCol = "date")              # aggregate up to month or year

summary(biscHyd)
coordinates(biscHyd) <- c("long", "lat")
proj4string(biscHyd) <- CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
# plot(bnp)
# plot(biscHyd, add = TRUE)
# 

## For each point, find name of nearest polygon (polygonLayer)
for (i in seq_along(unique(biscHyd$stn))) {
  biscHyd$subRegion[biscHyd$stn %in% unique(biscHyd$stn)[i]] <- suppressWarnings(polygonLayer$BOX_CODE[which.min(gDistance(masterCoords[masterCoords$stn == unique(biscHyd$stn)[i],], polygonLayer, byid=TRUE))])
  biscHyd$hectares[biscHyd$stn %in% unique(biscHyd$stn)[i]]  <- suppressWarnings(polygonLayer$HECTARES[which.min(gDistance(masterCoords[masterCoords$stn == unique(biscHyd$stn)[i],], polygonLayer, byid=TRUE))])
}

biscHyd.proj  <- biscHyd
biscHyd       <- as.data.frame(biscHyd)
biscHyd$m3dha <- biscHyd$m3d / biscHyd$hectares # m3 flow / day / hectare

###########################
#### back to water quality: interpolate linearly between samples. This is an area for improvement
###########################
biscHyd2 <- biscHyd 
biscHyd2[, grep(x = names(biscHyd2), pattern = "DISSOLVED"):grep(x = names(biscHyd2), pattern = "ORTHO.AS.P")] <- zoo::na.approx(biscHyd[,grep(x = names(biscHyd2), pattern = "DISSOLVED"):grep(x = names(biscHyd2), pattern = "ORTHO.AS.P")], na.rm = FALSE)


biscHyd2$salt.flux.kg <- biscHyd2$SALINITY * biscHyd2$m3d # kg salt/m3 * m3/day = kg salt/day
biscHyd2$N.flux.kg    <- (biscHyd2$NITRATE.NITRITE.N + biscHyd2$AMMONIA.N) * 1000  * biscHyd2$m3d # g/m3 * 1000g/kg * m3/day = kg N/day
biscHyd2$H.flux.kg    <- 10^-(biscHyd2$PH..FIELD) * 1.01 * biscHyd2$m3d  # (kmol/m3) *  (1.01 kg/kmol) * m3/d = kg/day
biscHyd2$P.flux.kg    <- biscHyd2$SALINITY * biscHyd2$m3d # kgP/m3 * m3/day = kg P/day
###########################



### plot structures and receiving basins in same color
polygonLayer$cols[polygonLayer$BOX_CODE %in% biscHyd.proj$subRegion] <- cols[as.numeric(as.factor(polygonLayer$BOX_CODE[polygonLayer$BOX_CODE %in% biscHyd.proj$subRegion]))]
biscHyd.proj$cols <- cols[as.numeric(as.factor(biscHyd.proj$subRegion))]


# plot(polygonLayer)
# plot(biscHyd.proj, add = TRUE)


plot(polygonLayer, col = polygonLayer$cols)
  # pointLabel(coordinates(polygonLayer), labels = polygonLayer$BOX_CODE)
plot(biscHyd.proj, add = TRUE, col = biscHyd.proj$cols)
  # pointLabel(coordinates(biscHyd.proj[1:length(biscHyd.proj$stn),]), labels = biscHyd.proj$stn) # can't figure out how to label points!
text(biscHyd.proj, labels = biscHyd.proj$stn, offset = 0.5, pos = 2)

### annual flux from each structure
# a <- ddply(biscHyd2, .(stn, year), summarise, kacft = sum(kacft, na.rm = TRUE), salt.flux.kg = sum(salt.flux.kg, na.rm = TRUE),             N.flux.kg = sum(N.flux.kg, na.rm = TRUE), H.flux.kg = sum(H.flux.kg, na.rm = TRUE),                   P.flux.kg = sum(P.flux.kg, na.rm = TRUE)) 
# ddply(a[a$year %in% 1980:1989, ], .(stn), summarise, mean(kacft, na.rm = TRUE)) # some values differ dramatically from table on page 49 of 1995 SWIM plan summary
ddply(biscHyd2, .(subRegion, year), summarise, kacft = sum(kacft, na.rm = TRUE), salt.flux.kg = sum(salt.flux.kg, na.rm = TRUE),             N.flux.kg = sum(N.flux.kg, na.rm = TRUE), H.flux.kg = sum(H.flux.kg, na.rm = TRUE),                   P.flux.kg = sum(P.flux.kg, na.rm = TRUE)) 


### spatial scale: whole bay.
flow.mnth <- ddply(biscHyd2, .(year, mo), summarise, m3 = sum(flow, na.rm = TRUE), m3ha = sum(m3dha, na.rm = TRUE))
flow.mnth$yrMo <- paste0(flow.mnth$year,"-", flow.mnth$mo)
flow.mnth$date <- zoo::as.yearmon(flow.mnth$yrMo, "%Y-%m")

flow.yr   <- ddply(biscHyd2, .(year), summarise, m3 = sum(flow, na.rm = TRUE), m3ha = sum(m3dha, na.rm = TRUE),
                   salt.flux.kg = sum(salt.flux.kg, na.rm = TRUE),             N.flux.kg = sum(N.flux.kg, na.rm = TRUE),
                   H.flux.kg = sum(H.flux.kg, na.rm = TRUE),                   P.flux.kg = sum(P.flux.kg, na.rm = TRUE))
flow.yr$year <- as.numeric(as.character(flow.yr$year))
flow.seas <- ddply(biscHyd2, .(seas, waterYr), summarise, m3 = sum(flow, na.rm = TRUE), m3ha = sum(m3dha, na.rm = TRUE),
                   salt.flux.kg = sum(salt.flux.kg, na.rm = TRUE),             N.flux.kg = sum(N.flux.kg, na.rm = TRUE),
                   H.flux.kg = sum(H.flux.kg, na.rm = TRUE),                   P.flux.kg = sum(P.flux.kg, na.rm = TRUE))
flow.seas$waterYr <- as.numeric(as.character(flow.seas$waterYr))


# 
# ggplot(flow.mnth, aes(y = m3 / 1e6, x = date)) + geom_line() + theme_classic() + xlab("") + ylab("inflow to bay (1e6 m3 per month)")
# ggplot(flow.yr, aes(y = m3 / 1e6, x = year)) + geom_line() + theme_classic() + xlab("calendar year") + ylab("inflow to bay (1e6 m3 per year)")
# ggplot(flow.seas, aes(y = m3 / 1e6, x = waterYr)) + geom_line() + theme_classic() + facet_grid(seas ~ .) + xlab("water year") + ylab("inflow to bay (1e6 m3 per season)")


### spatial scale: bay subregions
flow.mnth <- ddply(biscHyd2, .(year, mo, subRegion), summarise, m3 = sum(flow, na.rm = TRUE), ha = mean(hectares, na.rm = TRUE))
flow.mnth$yrMo <- paste0(flow.mnth$year,"-", flow.mnth$mo)
flow.mnth$date <- zoo::as.yearmon(flow.mnth$yrMo, "%Y-%m")

flow.yr   <- ddply(biscHyd2, .(year, subRegion), summarise, m3 = sum(flow, na.rm = TRUE), ha = mean(hectares, na.rm = TRUE),
                   salt.flux.kg = sum(salt.flux.kg, na.rm = TRUE),             N.flux.kg = sum(N.flux.kg, na.rm = TRUE),
                   H.flux.kg = sum(H.flux.kg, na.rm = TRUE),                   P.flux.kg = sum(P.flux.kg, na.rm = TRUE))
flow.yr$year <- as.numeric(as.character(flow.yr$year))
flow.seas <- ddply(biscHyd2, .(seas, waterYr, subRegion), summarise, m3 = sum(flow, na.rm = TRUE), ha = mean(hectares, na.rm = TRUE),
                   salt.flux.kg = sum(salt.flux.kg, na.rm = TRUE),             N.flux.kg = sum(N.flux.kg, na.rm = TRUE),
                   H.flux.kg = sum(H.flux.kg, na.rm = TRUE),                   P.flux.kg = sum(P.flux.kg, na.rm = TRUE))
flow.seas$waterYr <- as.numeric(as.character(flow.seas$waterYr))


# 
# ggplot(flow.mnth, aes(y = m3 / 1e6, x = date, col = subRegion)) + geom_line() + theme_classic() + facet_grid(. ~ subRegion) + xlab("") + ylab("inflow to bay (1e6 m3 per month)")
# ggplot(flow.mnth, aes(y = m3ha / 1e6, x = date, col = subRegion)) + geom_line() + theme_classic() + facet_grid(. ~ subRegion) + xlab("") + ylab("inflow to bay (1e6 m3 per ha per month)")
# 
# ggplot(flow.yr, aes(y = m3 / 1e6, x = year, col = subRegion)) + geom_line() + theme_classic() + facet_grid(. ~ subRegion) + xlab("calendar year") + ylab("inflow to bay (1e6 m3 per year)")
# ggplot(flow.yr, aes(y = m3ha / 1e6, x = year, col = subRegion)) + geom_line() + theme_classic() + facet_grid(. ~ subRegion) + xlab("calendar year") + ylab("inflow to bay (1e6 m3 per ha per year)")
# 
# ggplot(flow.seas, aes(y = m3 / 1e6, x = waterYr, col = subRegion)) + geom_line() + theme_classic() + facet_grid(seas ~ subRegion) + xlab("water year") + ylab("inflow to bay (1e6 m3 per season)")
# ggplot(flow.seas, aes(y = m3ha / 1e6, x = waterYr, col = subRegion)) + geom_line() + theme_classic() + facet_grid(seas ~ subRegion) + xlab("water year") + ylab("inflow to bay (1e6 m3 per ha per season)")
# 



```



Flows through \code{structs} were used to calculate annual water inflow to the bay through canals.



mass = (height$\cdot$a + b)^1/$\lambda$^ 


```{r Figure - flow to bay, fig.width = 6, fig.height = 4, message = FALSE, include=FALSE, echo=FALSE}

ggplot(flow.seas, aes(y = m3 / 1e6, x = waterYr, col = subRegion)) + geom_line() + theme_classic() + facet_grid(seas ~ subRegion) + xlab("water year") + ylab("inflow to bay (1e6 m3 per season)")
ggplot(flow.seas, aes(y = m3 / ha, x = waterYr, col = subRegion)) + geom_line() + theme_classic() + facet_grid(seas ~ subRegion) + xlab("water year") + ylab("inflow to bay (m3 per ha per season)")
```



**2.1.	Solute delivery from canals**


```{r annual solute delivery from canals, include=FALSE, echo=FALSE}
soluteDF <- melt(flow.seas, id.vars = c("seas", "waterYr", "subRegion", "ha"))

ggplot(soluteDF, aes(y = value, x = waterYr, col = subRegion)) + geom_line() + theme_classic() + facet_grid(variable ~ seas, scales = "free") + xlab("water year") + ylab("flux to bay (per season)")
ggplot(soluteDF, aes(y = value / ha, x = waterYr, col = subRegion)) + geom_line() + theme_classic() + facet_grid(variable ~ seas, scales = "free") + xlab("water year") + ylab("flux to bay (per ha per season)")


```



```{r solute delivery vs subregion concentrations, include=FALSE, echo=FALSE}
### combine wide datasets
head(flow.seas)
aves   <- dcast(combd.seas, seas + yr + subregion ~ param, value.var = "mean")
sds    <- dcast(combd.seas, seas + yr + subregion ~ param, value.var = "sd")
prop20 <- dcast(combd.seas, seas + yr + subregion ~ param, value.var = "propSub20")

names(aves)[c(2:3,4:ncol(aves))]     <- c("waterYr", "subRegion", paste0(names(aves)[c(4:ncol(aves))], ".mean"))
names(sds)[c(2:3,4:ncol(sds))]       <- c("waterYr", "subRegion", paste0(names(sds)[c(4:ncol(sds))], ".sd"))
names(prop20)[c(2:3,4:ncol(prop20))] <- c("waterYr", "subRegion", paste0(names(prop20)[c(4:ncol(prop20))], ".sub20"))



df <- join_all(list(flow.seas, aves, sds, prop20), by = c("seas", "waterYr", "subRegion"))

plot(df[, c(4, 6:11)])

ggplot(df, aes(y = SALINITY.mean, x = m3, col = subRegion)) + geom_point() + theme_classic()

```





